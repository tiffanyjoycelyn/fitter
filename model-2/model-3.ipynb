{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "from keras.utils import img_to_array, load_img\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.DataFrame(columns=['imagePath', 'label'])\n",
    "\n",
    "directories = {\n",
    "    \"ayam_goreng\": \"./dataset/ayam_goreng/\",\n",
    "    \"ayam_pop\": \"./dataset/ayam_pop/\",\n",
    "    \"daging_rendang\": \"./dataset/daging_rendang/\",\n",
    "    \"dendeng_batokok\": \"./dataset/dendeng_batokok/\",\n",
    "    \"gulai_ikan\": \"./dataset/gulai_ikan/\",\n",
    "    \"gulai_tambusu\": \"./dataset/gulai_tambusu/\",\n",
    "    \"telur_balado\": \"./dataset/telur_balado/\",\n",
    "    \"telur_dadar\": \"./dataset/telur_dadar/\",\n",
    "    \"tahu\": \"./dataset/tahu/\",\n",
    "    \"daun_singkong\": \"./dataset/daun_singkong/\",\n",
    "    \"nangka\": \"./dataset/nangka/\",\n",
    "    \"perkedel\": \"./dataset/perkedel/\",\n",
    "    \"nasi\" : \"./dataset/nasi/\"\n",
    "}\n",
    "\n",
    "for label, directory in directories.items():\n",
    "    for i in os.listdir(directory):\n",
    "        df = pd.concat([df, pd.DataFrame({'imagePath': [f\"{directory}/{i}\"], 'label': [label]})])\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "imgs = []\n",
    "\n",
    "for image_path in df['imagePath']:\n",
    "    img = load_img(image_path, target_size=(127, 127)).convert('RGB')\n",
    "    img_array = img_to_array(img) / 128\n",
    "    imgs.append(img_array)\n",
    "\n",
    "df['img'] = imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.25,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "x = np.array(df['img'].tolist())\n",
    "y = le.fit_transform(df['label'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "67/67 [==============================] - 20s 150ms/step - loss: 2.7246 - accuracy: 0.0931 - val_loss: 2.4394 - val_accuracy: 0.2505 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 2.5340 - accuracy: 0.1273 - val_loss: 2.3296 - val_accuracy: 0.2598 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 2.4667 - accuracy: 0.1455 - val_loss: 2.2623 - val_accuracy: 0.2673 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "67/67 [==============================] - 7s 105ms/step - loss: 2.3769 - accuracy: 0.1741 - val_loss: 2.0614 - val_accuracy: 0.3065 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "67/67 [==============================] - 7s 103ms/step - loss: 2.3568 - accuracy: 0.1886 - val_loss: 2.0927 - val_accuracy: 0.2748 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "67/67 [==============================] - 7s 103ms/step - loss: 2.3369 - accuracy: 0.1848 - val_loss: 2.0197 - val_accuracy: 0.3178 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "67/67 [==============================] - 7s 101ms/step - loss: 2.3100 - accuracy: 0.1858 - val_loss: 2.0356 - val_accuracy: 0.3084 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "67/67 [==============================] - 7s 99ms/step - loss: 2.2856 - accuracy: 0.2007 - val_loss: 2.0281 - val_accuracy: 0.3047 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 2.2461 - accuracy: 0.2068 - val_loss: 1.9151 - val_accuracy: 0.3514 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 2.2542 - accuracy: 0.2204 - val_loss: 1.9028 - val_accuracy: 0.3720 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "67/67 [==============================] - 7s 102ms/step - loss: 2.2230 - accuracy: 0.2120 - val_loss: 1.8865 - val_accuracy: 0.3738 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "67/67 [==============================] - 7s 103ms/step - loss: 2.2325 - accuracy: 0.2185 - val_loss: 2.1229 - val_accuracy: 0.3234 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "67/67 [==============================] - 7s 106ms/step - loss: 2.1645 - accuracy: 0.2443 - val_loss: 2.2895 - val_accuracy: 0.3271 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "67/67 [==============================] - 7s 101ms/step - loss: 2.2299 - accuracy: 0.2246 - val_loss: 1.9853 - val_accuracy: 0.3495 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "67/67 [==============================] - 7s 101ms/step - loss: 2.1942 - accuracy: 0.2246 - val_loss: 1.9645 - val_accuracy: 0.3757 - lr: 2.0000e-04\n",
      "Epoch 16/50\n",
      "67/67 [==============================] - 7s 104ms/step - loss: 2.1222 - accuracy: 0.2480 - val_loss: 2.1095 - val_accuracy: 0.3757 - lr: 2.0000e-04\n",
      "17/17 [==============================] - 1s 44ms/step - loss: 1.8865 - accuracy: 0.3738\n",
      "Test Accuracy: 37.38%\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Flatten, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Load the VGG16 base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(127, 127, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Add custom layers on top of VGG16\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(len(directories), activation='softmax')(x)\n",
    "\n",
    "# Combine the base model and custom layers\n",
    "model3 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model3.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=1e-6)\n",
    "\n",
    "# Train the model\n",
    "history = model3.fit(datagen.flow(x_train, y_train, batch_size=32),\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    epochs=50,\n",
    "                    callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model3.evaluate(x_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy * 100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
